{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a65fcd0-ee9b-491b-8b50-eac60b4239eb",
   "metadata": {},
   "source": [
    "# Math, statistics:\n",
    "\n",
    "- Calculus\n",
    "- Linear algebra\n",
    "- Probability\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872cf73-0b2d-41f4-a049-1726104779a8",
   "metadata": {},
   "source": [
    "# Разные виды анализа\n",
    "\n",
    "## Описательный / дескриптивный (descriptive)\n",
    "Цель: отразить, что уже произошло. С помощью простых инструментов показать основные тренды с некоторой глубиной по истории. \n",
    "Пример: график/таблица доли заказов, которые были созданы, и мы смогли найти на них курьера, например, с подсвеченными днями с плохими показателями. Далее будем называть эту метрику «вывозимость».\n",
    "\n",
    "## Разведочный (exploratory) анализ\n",
    "Цель: понять, почему произошло именно так. Провести детальную аналитику факторов, повлиявших на произошедшее, выяснить причину произошедшего.\n",
    "Пример: после этапа описательной аналитики продаж мы выяснили, что в один из дней были плохие показатели по уровню вывозимости. Далее мы перебираем все факторы, влияющие на эту метрику, и выясняем, что она снизилась из-за того, что мотивации были поставлены неправильно — не в том районе, где был сосредоточен по итогу спрос.\n",
    "\n",
    "## Индуктивный (inferential) анализ\n",
    "Цель: на основе аналитики конкретной ситуации сделать вывод о\n",
    "проблемах бизнеса в целом.\n",
    "Пример: мы увидели, что вывозимость снижается из-за неправильно поставленных мотиваций, и делаем предположение о том, что в целом у нас есть проблемы с ней. Проводим аналитику и подтверждаем, что часто не угадываем с моментом времени и районом, когда и куда нужно поставить мотивации.\n",
    "\n",
    "## Прогностический / предиктивный (predictive) анализ\n",
    "Цель: изучить взаимосвязи между переменными на основе имеющихся данных и разработать модель, способную прогнозировать значения для новых, неполных или будущих точек.\n",
    "Пример: построили модели спроса и предложения по районам города по часам. На основе нее сами планируем мотивации в районах, где ожидаем дисбаланс спроса и предложения.\n",
    "\n",
    "## Прескриптивный (prescriptive) анализ\n",
    "Цель: автоматизировать процесс принятия решений на основе построенных прогнозов.\n",
    "Пример: по построенным моделям строим системы принятия решений о том, в какой район стоит ставить мотивации. Например, на основе исторических данных об эффективности этих мотиваций и среднем чеке заказов из этих районов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfa6c1e-2fa0-4e45-b4cf-54c90298a11f",
   "metadata": {},
   "source": [
    "## - Descriptive Analytics (what happened in the past?) = описательный, дескриптивный\n",
    "\n",
    "Распределение.\n",
    "\n",
    "Five-number summary.\n",
    "\n",
    "Меры среднего — это описательные статистики, используемые для измерения магистральной тенденции или типичного значения в датасете.\n",
    "\n",
    "Меры разброса — описательные статистики, используемые для измерения степени вариации или разброса значений в датасете.\n",
    "\n",
    "Размах — разность между наибольшим и наименьшим значениями.\n",
    "\n",
    "Квантиль — значение, которое разделяет упорядоченный набор данных на равные или пропорциональные части. Квантили — это обобщение понятия медианы — числа, больше и меньше которого находится одинаковое количество элементов выборки.\n",
    "Частный случай квантиля — это квартили и процентили.\n",
    "\n",
    "Квартили:\n",
    "\n",
    "Q1, или первый квартиль, делит выборку в следующем соотношении: 25% выборки меньше значения квартиля, 75% больше значения квартиля.\n",
    "Q2, или медиана, делит выборку в соотношении 50% на 50%.\n",
    "Q3, или третий квартиль, делит выборку в следующем соотношении 75% на 25%.\n",
    "X-процентилем называется квантиль X/100. Следовательно, медиана является 50-м процентилем, а первый и третий квартиль — 25-м и 75-м процентилями соответственно.\n",
    "\n",
    "Интерквантильный размах — это разность между третьим и первым квартилем.\n",
    "Чем больше интерквартильный размах, тем более неоднородны данные.\n",
    "\n",
    "Среднее — это частное от деления суммы значений на количество этих значений. Оно позволяет быстро понять порядок изучаемой величины, но имеет серьезный недостаток: оно очень неустойчиво к выбросам. Также оно плохо описывает неоднородные наборы данных.\n",
    "\n",
    "Выбросы — значения, которые выделяются из общей выборки.\n",
    "\n",
    "Медиана — значение, которое разделяет набор данных пополам.  В отличие от среднего, она устойчива к выбросам и хорошо показывает себя на несбалансированных выборках.\n",
    "\n",
    "Стандартное отклонение - это наиболее часто используемая мера разброса в реальных аналитических задачах. Она показывает, как далеко в среднем находятся элементы выборки от своего среднего.\n",
    "\n",
    "Мода — наиболее часто встречающееся значение в выборке. В отличие от среднего и квартилей, которые хорошо подходят и для дискретных, и для непрерывных данных, мода на практике обычно используется только с дискретными данными.\n",
    "\n",
    "Симметричность:\n",
    "Асимметрия определяется степенью скошенности графика влево или вправо, а эксцесс — мерой его высоты.\n",
    "Коэффициент эксцесса характеризует остроконечность в случае положительных значений или пологость в случае отрицательных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144183a6-56f5-4d27-95e6-22c3848d88af",
   "metadata": {},
   "source": [
    "## - Diagnostic Analytics (why did it happened in the past?) = диагностический\n",
    "\n",
    "### -> разведочный (exploratory)\n",
    "\n",
    "- Data visualization: complex relationships and patterns by presenting data visually and clearly.\n",
    "- \n",
    "- Hypothesis testing: hypothesis about the relationship between variables\n",
    "- Regression analysis: the relationship between a dependent variable and one or more independent variables\n",
    "- Anomaly detection: unusual or abnormal patterns in the data that might indicate underlying issues, outliers or deviations from expected behavior.\n",
    "- Root cause analysis: fundamental reasons behind an event or outcome, investigating contributing factors to identify the primary cause.\n",
    "- Correlation analysis: the strengths and direction of relationships between variables\n",
    "- Cohort analysis: groups data into segments, also known as cohorts, based on shared characteristics and then compares their behaviors or outcomes over time, insights into how different groups respond to changes.\n",
    "- Factor analysis: underlying factors that contribute to interrelationships among variables, helping reduce data complexity and find common themes.\n",
    "- Case-control studies: Compares individuals associated with a particular outcome or case to individuals in a control group who are not to identify factors associated with the outcome. Healthcare companies typically use this technique.\n",
    "- Time series analysis: Examines data collected at different intervals to find trends, seasonality, and relationships between variables over time.\n",
    "- Simulation modeling: Uses mathematical or computational methods to simulate real-world scenarios. These simulations can help you understand how variable changes impact outcomes and provide insights into different scenarios.\n",
    "\n",
    "\n",
    "        Случайные величины\n",
    "  \n",
    "        Различные виды распределений\n",
    "          Нормальное распределение\n",
    "          Логнормальное распределение\n",
    "          Распределение Пуассона\n",
    "          Биномиальное распределение\n",
    "\n",
    "        метод Монте-Карло\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23bd5f7-c413-4f25-abee-cd9087cbb712",
   "metadata": {},
   "source": [
    "## Inferential Analytics = индуктивный\n",
    "\n",
    "- методы отбора репрезентативных выборок.\n",
    "- доверительные интервалы для оценки неизвестных параметров.\n",
    "- как формулировать и проверять статистические гипотезы.\n",
    "- понятие p-value и его роль в проверке гипотез.\n",
    "- ЗБЧ и ЦПТ, их роль в статистическом анализе.\n",
    "- A/B-тестирование и его применение.\n",
    "- t-критерий и z-критерий для проверки гипотез.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Индуктивный анализ позволяет на основе небольшой выборки сделать обобщающие выводы обо всем множестве значений.\n",
    "\n",
    "Генеральная совокупность (ГС) — множество всех объектов для наблюдения.\n",
    "\n",
    "Выборка — подмножество из генеральной совокупности, которое мы фактически можем исследовать.\n",
    "\n",
    "«Правильная» выборка называется репрезентативной, и ее параметры, например, какой-то набор метрик, должны иметь схожие значения со значениями генеральной совокупности.\n",
    "\n",
    "Выборочное среднее — это среднее арифметическое каких-либо характеристик выборки. Выборочное среднее  — это «аналог» математического ожидания для выборки.\n",
    "\n",
    "Стандартная ошибка — это мера точности оценки среднего, которая показывает, насколько мы можем быть уверены в том, что среднее значение действительно близко к истинному. \n",
    "\n",
    "Доверительный интервал — это диапазон, в котором с некоторой вероятностью находится параметр. Эта вероятность выбирается заранее и называется доверительной вероятностью. Чаще всего используют два значения доверительной вероятности — 95% и 99%.\n",
    "\n",
    "Тестирование гипотез — это процесс проверки предположения на основе имеющихся данных. В статистике принято формулировать гипотезы в виде нулевой H0 и альтернативной H1. Как правило, нулевая гипотеза говорит о сохранении текущего положения дел (то есть о том, что изменения не повлияли на показатель). Альтернативная гипотеза наоборот представляет собой утверждение, что изменение повлияло на выбранный нами показатель.\n",
    "\n",
    "P-value — это вероятность, с которой мы можем отклониться на такое или еще более экстремальное значение в рамках нашего распределения. P-value показывает, насколько вероятно такое распределение данных, которое мы видим в выборке, при условии, что нулевая гипотеза верна. Если p-value меньше заданного уровня значимости альфа, мы можем отвергнуть H0.\n",
    "\n",
    "ЗБЧ — Закон больших чисел. Суть закона больших чисел можно пересказать следующим образом: при увеличении размера выборки среднее значение этой выборки стремится к среднему значению генеральной совокупности.\n",
    "\n",
    "ЦПТ — Центральная предельная теорема. ЦПТ говорит о том, что если взять много выборок из ГС, то выборочные средние будут распределены по нормальному закону. Причём неважно, как распределены данные в самой ГС.\n",
    "\n",
    "А/В-тестирование — это испытание двух версий одного и того же продукта или сервиса с целью выяснить, какая из них работает лучше. Например, вы можете провести A/B-тест двух разных моделей реализации продуктов в гипермаркете, чтобы увидеть, какой из них приносит бОльшую прибыль.\n",
    "\n",
    "T-тест Стьюдента используется, чтобы определить, отличаются ли средние значения двух выборок и есть ли между двумя группами данных значимые различия.\n",
    "\n",
    "Критерий Манна-Уитни используется для сравнения двух независимых выборок по уровню какого-либо признака.\n",
    "\n",
    "Z-тест используется для сравнения пропорции, например для определения доли мужчин в общей численности населения страны или конверсии в покупку от общего числа посетителей.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e303a-710d-43a7-86c4-f4b62393db9c",
   "metadata": {},
   "source": [
    "## - Predictive Analytics (what will happen in the future?) = предиктивный, прогностический\n",
    "\n",
    "#### -- прогнозы с помощью линейной и логистической регрессий (задачи регрессии и классификации)\n",
    "\n",
    "- LinearRegression\n",
    "Этот класс представляет собой модель простой линейной регрессии, которая пытается установить линейную зависимость между одним или несколькими признаками и целевой переменной.\n",
    "\n",
    "        Mean_squared_error\n",
    "        Вычисляет среднеквадратичную ошибку между фактическими и предсказанными значениями.\n",
    "        \n",
    "        Mean_absolute_error\n",
    "        Рассчитывает среднюю абсолютную ошибку между фактическими и предсказанными значениями.\n",
    "        \n",
    "        R2_score\n",
    "        Оценивает долю объясненной дисперсии в данных, которую модель смогла объяснить.\n",
    "\n",
    "\n",
    "- LogisticRegression\n",
    "Этот класс реализует модель логистической регрессии, которая используется для бинарной классификации (предсказание принадлежности к одной из двух категорий) и многоклассовой классификации.\n",
    "\n",
    "        Accuracy_score\n",
    "        Вычисляет Accuracy — отношение количества правильно классифицированных объектов ко всем объектам в выборке.\n",
    "        \n",
    "        Precision_score\n",
    "        Вычисляет Precision — отношение количества правильно классифицированных положительных примеров к общему количеству положительных примеров, предсказанных моделью.\n",
    "        \n",
    "        Recall_score\n",
    "        Вычисляет Recall — отношение количества правильно классифицированных положительных примеров к общему количеству истинных положительных примеров в выборке.\n",
    "\n",
    "\n",
    "#### -- временные ряды и его компоненты\n",
    "- стационарность, проверять временной ряд на стационарность.\n",
    "- библиотека Prophet для прогнозирования временных рядов.\n",
    "- альтернативные способы прогнозирования временных рядов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b92a708-5179-4eb4-96a5-012af0c3022a",
   "metadata": {},
   "source": [
    "## - Prescriptive Analytics (how can we make it happen?) = прескриптивный\n",
    "\n",
    "Prescriptive analytics, a crucial type of data analytics, is essential for making data-driven decisions in business and organizational contexts. As a data analyst, the goal of prescriptive analytics is to recommend various actions using predictions on the basis of known parameters to help decision makers understand likely outcomes. Prescriptive analytics employs a blend of techniques and tools such as algorithms, machine learning, computational modelling procedures, and decision-tree structures to enable automated decision making. Therefore, prescriptive analytics not only anticipates what will happen and when it will happen, but also explains why it will happen, contributing to the significance of a data analyst’s role in an organization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e75b79-e10f-48ce-a2fb-c74c21221566",
   "metadata": {},
   "source": [
    "# Data flow:\n",
    "\n",
    "- collecting:\n",
    "    - databases (SQL, cloud)\n",
    "    - datasets (csv, xls, json)\n",
    "    - api\n",
    "    - web scrapping\n",
    "- storage, management\n",
    "- preprocessing:\n",
    "    - cleaning errors\n",
    "    - filling na\n",
    "    - cleaning duplicates\n",
    "    - standartisation (format)\n",
    "    - normalisation (range)\n",
    "    - Агрегация: Процесс объединения данных из разных источников для получения сводной информации (например, подсчет среднего значения, суммы и т.д.).\n",
    "- EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf3c5a-6dbc-4cd0-a7ff-56ca8463b11c",
   "metadata": {},
   "source": [
    "# Visualisation\n",
    "\n",
    "Подбрать оптимальный тип диаграммы — линейный график, гистограмму, диаграмму рассеяния, box-plot.\n",
    "\n",
    "Настроить элементы графика — легенду, оси и маркировку.\n",
    "\n",
    "Рисовать тепловые карты для обозначения корреляции между признаками.\n",
    "\n",
    "- types:\n",
    "    - Линейные графики: Используются для отображения изменений значений во времени.\n",
    "    - Столбчатые графики: Подходят для сравнения категориальных данных.\n",
    "    - Круговые диаграммы: Используются для отображения долей от общего.\n",
    "    - Гистограммы: Позволяют анализировать распределение данных.\n",
    "    - Рассеяние (scatter plots): Используются для выявления взаимосвязей между двумя переменными.\n",
    "    - Коробочные графики (box plots): Позволяют визуализировать распределение и выявлять выбросы.\n",
    "- Pyhton - matplotlib, seaborn, plotly\n",
    "- Excel - Power\n",
    "- BI - PowerBI, Tableau, \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cc7298-b371-46e2-b54d-8eec0edc46f4",
   "metadata": {},
   "source": [
    "# [lib] Pandas\n",
    "\n",
    "Чтение данных из файла\n",
    "\n",
    "Просмотр данных \n",
    "\n",
    "Фильтрация данных\n",
    "\n",
    "Добавление и удаление столбцов\n",
    "\n",
    "Группировка данных\n",
    "\n",
    "Запись данных в файл\n",
    "\n",
    "- Дескриптивный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c1a176-9eab-4e96-8bac-d331ed1ca27f",
   "metadata": {},
   "source": [
    "# [lib] Numpy\n",
    "\n",
    "    Cоздание массивов.\n",
    "    \n",
    "    Арифметические операции: сложение, вычитание, умножение, деление и возведение в степень.\n",
    "    \n",
    "    Линейная алгебра: операции с матрицами, такие как умножение, вычисление определителей и собственных значений.\n",
    "    \n",
    "    Статистика: функции для расчета среднего, медианы, стандартного отклонения и т.д.\n",
    "    \n",
    "    Преобразования Фурье: для анализа сигналов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0fec57-7447-4b12-a6cd-f08f47007aa7",
   "metadata": {},
   "source": [
    "# [lib] SciPy\n",
    "это библиотека для научных и инженерных расчётов на Python. \n",
    "Она предоставляет инструменты для работы с массивами, оптимизации, обработки сигналов, статистики и многого другого. \n",
    "Эта библиотека включает множество модулей.  Мы воспользовались модулем stats, из которого и взяли нашу функцию norm.\n",
    "\n",
    "Массив случайных чисел, выбранных из указанного логнормального распределения\n",
    "scipy.stats.lognorm.rvs(s, loc=0, scale=1, size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05322e8-bd9a-4915-a37d-c5b589f12975",
   "metadata": {},
   "source": [
    "# [lib] Matplotlib | Plotly\n",
    "\n",
    "- Простая визуализация\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3491d5a1-3059-4732-9b8c-105cfed60c30",
   "metadata": {},
   "source": [
    "# [lib] Seaborn\n",
    "\n",
    "1. Графики распределения данных\n",
    "\n",
    "Эти графики помогают понять, как распределены значения переменных. Они дают представление о форме распределения данных, наличии выбросов и плотности данных.\n",
    "\n",
    "- distplot(): Этот график объединяет гистограмму (для отображения частоты значений) и график оценки плотности (для более гладкого отображения распределения).\n",
    "- kdeplot(): Отображает оценку плотности распределения, создавая плавную линию, которая показывает вероятностную плотность данных.\n",
    "- histplot(): Гистограмма, которая показывает распределение данных в виде столбцов. Она отображает количество элементов, попадающих в разные интервалы (бины).\n",
    "- rugplot(): Дополняет распределительные графики, добавляя маленькие полоски (штрихи) вдоль оси, указывающие на местоположение данных.\n",
    "\n",
    "2. Категориальные данные\n",
    "\n",
    "Категориальные графики помогают визуализировать данные, распределённые по категориям, такие как группы или классы.\n",
    "\n",
    "- boxplot(): Коробчатая диаграмма, которая показывает медиану, нижний и верхний квартиль, а также выбросы. Хорошо подходит для отображения диапазона и распределения данных.\n",
    "- violinplot(): Виолончельная диаграмма, объединяет в себе свойства boxplot и kdeplot. Она показывает распределение данных и их плотность, что даёт более детальное представление о форме распределения.\n",
    "- stripplot(): Отображает каждое значение как точку на графике, позволяя увидеть разброс данных в пределах категории.\n",
    "- swarmplot(): Похож на stripplot, но с дополнительной логикой для предотвращения перекрытия точек. Это делает график более читаемым при наличии большого количества данных.\n",
    "\n",
    "3. Регрессионные графики\n",
    "\n",
    "Используются для отображения линий тренда и визуализации связи между переменными.\n",
    "\n",
    "- regplot(): Показывает регрессионную линию, добавленную к точкам данных, для иллюстрации взаимосвязи между двумя переменными.\n",
    "- lmplot(): Более расширенная версия regplot. Она поддерживает разделение данных по категориям (например, по цвету), что полезно для визуализации многомерных данных.\n",
    "\n",
    "\n",
    "4. Матрицы данных\n",
    "\n",
    "Эти графики помогают визуализировать сложные отношения в данных, такие как корреляции или кластерные структуры.\n",
    "\n",
    "- heatmap(): Тепловая карта, которая используется для визуализации значений в виде цветной матрицы. Часто применяется для анализа корреляций между переменными.\n",
    "- clustermap(): Похожа на heatmap, но добавляет иерархическую кластеризацию, которая группирует похожие строки и столбцы.\n",
    "\n",
    "5. Сетевые графики\n",
    "\n",
    "Помогают визуализировать отношения между множеством переменных.\n",
    "\n",
    "- pairplot(): Отображает графики всех пар переменных в сетке. Это позволяет изучить все возможные взаимосвязи между переменными в наборе данных.\n",
    "- jointplot(): Объединяет диаграмму рассеяния с гистограммами или kdeplot по осям X и Y, визуализируя отношения между двумя переменными и их распределение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d117291-d71c-48ed-874c-b1ff2cdaec57",
   "metadata": {},
   "source": [
    "# Machine Learning:\n",
    "\n",
    "- Обучение с учителем:\n",
    "    - Линейная регрессия: Используется для предсказания непрерывных значений, например, цены недвижимости.\n",
    "    - Деревья решений: Структурированные модели, которые принимают решения на основе последовательных вопросов о входных данных.\n",
    "    - Нейронные сети: Сложные модели, состоящие из множества слоев, которые могут обучаться на больших объемах данных для выполнения задач классификации и регрессии.\n",
    "\n",
    "- Обучение без учителя (например, кластеризация) — используется для нахождения скрытых структур в данных без заранее известных меток.\n",
    "    - Кластеризация: Разделяет данные на группы (кластеры) на основе схожести. Например, алгоритмы K-средних и иерархическая кластеризация.\n",
    "    - Метод главных компонент (PCA): Используется для уменьшения размерности данных, сохраняя при этом наиболее важные характеристики.\n",
    "\n",
    "- Обучение с подкреплением — основано на взаимодействии агента с окружающей средой для достижения максимальной выгоды.\n",
    "    - Q-обучение: Метод, который позволяет агенту обучаться оптимальной стратегии действий в среде, основываясь на полученных наградах.\n",
    "    - Deep Q-Networks (DQN): Комбинация нейронных сетей и Q-обучения, используемая для решения сложных задач, таких как игра в видеоигры.\n",
    "\n",
    "## Процесс работы с моделями:\n",
    "\n",
    "1. Обучение модели\n",
    "2. Валидация модели\n",
    "3. Тестирование модели\n",
    "4. Деплоймент модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e43db9a-f299-4b4e-b7ff-766ced38f842",
   "metadata": {},
   "source": [
    "# [lib] Scikit-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "инструменты для предобработки данных, включая масштабирование (нормализация), кодирование категориальных переменных, обработку пропущенных значений и другие методы.\n",
    "\n",
    "\n",
    "    Классификация: SVM, случайные леса, логистическая регрессия, K-ближайших соседей и другие.\n",
    "    Регрессия: линейная регрессия, полиномиальная регрессия, регрессия на основе деревьев решений.\n",
    "    Кластеризация: K-средние, иерархическая кластеризация, DBSCAN и другие.\n",
    "    Снижение размерности: PCA (метод главных компонент), t-SNE и другие.\n",
    "\n",
    "    функции для оценки качества моделей, такие как кросс-валидация и различные метрики (точность, полнота, F1-меры и другие). Также доступны методы для отбора признаков (feature selection).\n",
    "\n",
    "### Основные компоненты Scikit-learn\n",
    "\n",
    "- Импортирование библиотеки: Прежде чем использовать Scikit-learn, необходимо импортировать нужные модули.\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "- Загрузка и подготовка данных:\n",
    "\n",
    "    data = pd.read_csv('data.csv')  # Замените 'data.csv' на ваш файл\n",
    "    X = data.drop('target', axis=1)  # Признаки\n",
    "    y = data['target']  # Целевая переменная\n",
    "\n",
    "- Разделение данных на обучающую и тестовую выборки: Обычно данные делятся на обучающую и тестовую выборки для оценки модели.\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "- Создание и обучение модели: Вы можете выбрать нужный алгоритм и обучить модель на обучающей выборке.\n",
    "\n",
    "    model = LogisticRegression()  # Создание модели логистической регрессии\n",
    "    model.fit(X_train, y_train)   # Обучение модели\n",
    "\n",
    "- Оценка модели: После обучения модели необходимо оценить её производительность на тестовой выборке.\n",
    "\n",
    "    y_pred = model.predict(X_test)  # Предсказание на тестовой выборке\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # Оценка точности\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dedad68-c8d2-4627-a8e6-99186467cad8",
   "metadata": {},
   "source": [
    "1. **Классическое обучение**  \n",
    "   - **Без учителя**  \n",
    "     - Кластеризация:  \n",
    "       - Mean-Shift  \n",
    "       - K-Means  \n",
    "       - Fuzzy C-Means  \n",
    "       - DBSCAN  \n",
    "       - Agglomerative  \n",
    "     - Поиск правил:  \n",
    "       - Euclat  \n",
    "       - Apriori  \n",
    "       - FP-Growth  \n",
    "   - **С учителем**  \n",
    "     - Классификация:  \n",
    "       - Naive Bayes  \n",
    "       - K-NN  \n",
    "       - SVM  \n",
    "       - Decision Trees  \n",
    "     - Регрессия:  \n",
    "       - Linear Regression  \n",
    "       - Polynomial Regression  \n",
    "       - Ridge/Lasso Regression  \n",
    "   - **Уменьшение размерности (обобщение)**  \n",
    "     - t-SNE  \n",
    "     - PCA  \n",
    "     - LSA  \n",
    "     - SVD  \n",
    "     - LDA\n",
    "\n",
    "2. **Обучение с подкреплением**  \n",
    "   - Генетический алгоритм  \n",
    "   - Q-Learning  \n",
    "   - SARSA  \n",
    "   - Deep Q-Network (DQN)  \n",
    "   - A3C\n",
    "\n",
    "3. **Ансамблевые методы**  \n",
    "   - Стекинг  \n",
    "   - Беггинг  \n",
    "   - Бустинг:  \n",
    "     - AdaBoost  \n",
    "     - XGBoost  \n",
    "     - LightGBM  \n",
    "     - CatBoost\n",
    "\n",
    "4. **Нейросети и глубокое обучение**  \n",
    "   - Convolutional Neural Networks (CNN):  \n",
    "     - DCNN  \n",
    "   - Recurrent Neural Networks (RNN):  \n",
    "     - LSTM  \n",
    "     - GRU  \n",
    "   - Generative Adversarial Networks (GAN)  \n",
    "   - Autoencoders  \n",
    "   - Перцептроны (MLP)  \n",
    "   - seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fc40b9-a773-4768-a1e6-e02be8e91a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef7c35f-4def-4b38-9677-9b83a4daa039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
